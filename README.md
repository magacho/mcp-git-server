# Servidor de Recupera√ß√£o de Contexto para Reposit√≥rios Git (MCP Server)

Este projeto fornece um servidor de API autocontido em Docker que clona um reposit√≥rio Git p√∫blico, o indexa usando modelos de embedding da OpenAI e exp√µe um endpoint para buscar trechos de c√≥digo e documenta√ß√£o relevantes para uma pergunta em linguagem natural.

√â a pe√ßa de "Recupera√ß√£o" (Retrieval) para um sistema de RAG (Retrieval-Augmented Generation), projetada para alimentar um agente de IA externo (como um workflow no n8n) com o contexto necess√°rio para responder perguntas sobre uma base de c√≥digo.

### ‚ú® Funcionalidades

-   **Embeddings Flex√≠veis:** Suporte a embeddings locais gratuitos (Sentence Transformers) ou OpenAI (pago)
-   **Configura√ß√£o Zero:** Funciona sem chaves de API - embeddings locais por padr√£o
-   **Configur√°vel via Vari√°veis de Ambiente:** Aponte para qualquer reposit√≥rio Git p√∫blico sem alterar o c√≥digo
-   **Cache Persistente:** O banco de dados vetorial √© criado na primeira execu√ß√£o e reutilizado
-   **API Simples:** Endpoints REST para busca e monitoramento
-   **Pronto para Produ√ß√£o:** Container Docker otimizado com usu√°rio n√£o-root
-   **Estimativa de Custos:** Mostra custos estimados para diferentes provedores

### üöÄ Como Usar

#### Pr√©-requisitos

1.  **Docker** instalado e em execu√ß√£o na sua m√°quina.
2.  Uma **API Key da OpenAI**. Voc√™ pode obter uma em [platform.openai.com/api-keys](https://platform.openai.com/api-keys).

#### Executando com Docker

**Modo Gratuito (Padr√£o - Embeddings Locais):**
```bash
docker run -p 8000:8000 \
  -e REPO_URL="https://github.com/n8n-io/n8n.git" \
  -e REPO_BRANCH="master" \
  -v ./mcp_data/chroma_db:/app/chroma_db \
  --name mcp-server \
  flaviomagacho/mcp-git-server:latest
```

**Modo OpenAI (Pago - Alta Qualidade):**
```bash
docker run -p 8000:8000 \
  -e REPO_URL="https://github.com/n8n-io/n8n.git" \
  -e REPO_BRANCH="master" \
  -e EMBEDDING_PROVIDER="openai" \
  -e OPENAI_API_KEY="SUA_CHAVE_API_SEGURA" \
  -v ./mcp_data/chroma_db:/app/chroma_db \
  --name mcp-server \
  flaviomagacho/mcp-git-server:latest
```

#### Build e Teste Local

```bash
# Clone e build
git clone https://github.com/magacho/mcp-git-server.git
cd mcp-git-server
docker build -t mcp-git-server .

# Teste com reposit√≥rio pequeno
docker run -p 8000:8000 \
  -e REPO_URL="https://github.com/octocat/Hello-World.git" \
  -e REPO_BRANCH="master" \
  mcp-git-server

# Verificar status (em outro terminal)
curl http://localhost:8000/health

# Usar com seu reposit√≥rio
docker run -p 8000:8000 \
  -e REPO_URL="https://github.com/seu-usuario/seu-repo.git" \
  -e REPO_BRANCH="main" \
  -v ./data/chroma_db:/app/chroma_db \
  mcp-git-server
```


### üîß Configura√ß√£o (Vari√°veis de Ambiente)

#### Obrigat√≥rias
-   `REPO_URL` (obrigat√≥rio): A URL `.git` do reposit√≥rio p√∫blico a ser indexado.

#### Opcionais - Reposit√≥rio
-   `REPO_BRANCH`: A branch que ser√° clonada para o MCP Server (padr√£o: `main`)

#### Opcionais - Embeddings
-   `EMBEDDING_PROVIDER`: Provedor de embeddings (padr√£o: `sentence-transformers`)
  - `sentence-transformers` - Gratuito, boa qualidade
  - `huggingface` - Gratuito, boa qualidade  
  - `openai` - Pago, alta qualidade
-   `OPENAI_API_KEY`: Chave da API OpenAI (necess√°ria apenas para `openai`)
-   `ST_EMBEDDING_MODEL`: Modelo Sentence Transformers (padr√£o: `all-MiniLM-L6-v2`)
-   `HF_EMBEDDING_MODEL`: Modelo HuggingFace (padr√£o: `sentence-transformers/all-MiniLM-L6-v2`)
-   `TOKEN_COUNT_METHOD`: M√©todo de contagem (padr√£o: `local`)

### ü§ñ Provedores de Embedding

#### Sentence Transformers (Padr√£o - Gratuito) ‚≠ê
- **Qualidade**: Boa
- **Custo**: Gratuito
- **Velocidade**: M√©dia (processamento local)
- **Configura√ß√£o**: Autom√°tica, sem chaves necess√°rias
- **Recomendado para**: Uso geral, desenvolvimento, testes

#### HuggingFace (Gratuito)
- **Qualidade**: Boa
- **Custo**: Gratuito
- **Velocidade**: M√©dia (processamento local)
- **Configura√ß√£o**: Autom√°tica, sem chaves necess√°rias
- **Recomendado para**: Modelos espec√≠ficos, multil√≠ngue

#### OpenAI (Pago)
- **Qualidade**: Alta
- **Custo**: ~$0.0001 por 1K tokens
- **Velocidade**: R√°pida (API)
- **Configura√ß√£o**: Requer `OPENAI_API_KEY`
- **Recomendado para**: Produ√ß√£o com alta qualidade

### ÔøΩ In√≠cio  R√°pido (Gratuito)

O servidor agora usa **embeddings locais por padr√£o** - sem necessidade de chaves de API!

```bash
# Modo padr√£o - completamente gratuito
docker run -p 8000:8000 \
  -e REPO_URL="https://github.com/n8n-io/n8n.git" \
  -v ./mcp_data/chroma_db:/app/chroma_db \
  flaviomagacho/mcp-git-server:latest
```

Acesse: `http://localhost:8000` para verificar o status.

### üîå Endpoints da API

**`GET /`** - Status do servidor
**`GET /health`** - Health check
**`GET /embedding-info`** - Informa√ß√µes sobre configura√ß√£o de embeddings

**`POST /retrieve`** - Busca por fragmentos de contexto relevantes

**Corpo da Requisi√ß√£o (JSON):**
```json
{
  "query": "Sua pergunta sobre o c√≥digo aqui",
  "top_k": 5
}
```

**Exemplo com `curl`:**
```bash
curl -X POST "http://localhost:8000/retrieve" \
-H "Content-Type: application/json" \
-d '{"query": "Como o n8n gerencia credenciais?", "top_k": 3}'
```

**Verificar configura√ß√£o:**
```bash
curl http://localhost:8000/embedding-info
```

---

### üó∫Ô∏è Roadmap

Confira o [ROADMAP.md](ROADMAP.md) para ver as funcionalidades planejadas.

---

*Este projeto foi criado em [10 de Outubro de 2025].*

